{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee7f6fb-5b42-4527-a08e-3fe4a80c4005",
   "metadata": {},
   "source": [
    "## Scientists Database Creator\n",
    "\n",
    "- The intention is to crawl through various website to create a database of (Indian) scientists working in physics and related fields\n",
    "\n",
    "- Results will be stored in the followng structure\n",
    "\n",
    "    ```\n",
    "project root\n",
    "|\n",
    "│   code.ipynb\n",
    "|\n",
    "└───database folder\n",
    "        |\n",
    "        │   high_energy_physics.csv\n",
    "        |\n",
    "        │   strongly_correlated_electrons.csv\n",
    "        |\n",
    "        │   quantum_magnetism.csv\n",
    "        |\n",
    "        |   low_dimensional_materials.csv\n",
    "```\n",
    "\n",
    "\n",
    "- Websites to crawl include google scholar and those of institutes like the IITs, IISERs, etc.\n",
    "\n",
    "- The code will be structured in the form of separate modules for each website.\n",
    "- Each module outputs results in a common format. This common format will be a dictionary, of the form\n",
    "\n",
    "`results={'complex_networks':[[Name 1, Affil 1, Webpage 1, Interests 1], [Name 2, Affil 2, Webpage 2, Interests 2]], 'quantum_magnetism':[[...]]}`\n",
    "\n",
    "- In other words, the keys of the dictionary are the interests, and the data of each key is a list. This list is itself formed by several lists, each of these smaller lists giving the information for a particular scientist. \n",
    "\n",
    "- Only the information of those scientits who have that particular interest will enter that particular key.\n",
    "\n",
    "- As an example, lets say the results are as follows. Scientist A1 with affiliation B1 has interests X1 and X2, while scientist A2 with affiliation B2 has interests X2 and X3. Then, the complete dictionary is `results={X1: [[A1, B1, \"X1, X2\"]], X2: [[A1, B1, \"X1, X2\"],[A2, B2, \"X2, X3\"]], X3: [[A2, B2, \"X2, X3\"]]}`\n",
    "\n",
    "- Each of these separate keys will be written to individual files, `X1.csv, X2.csv` and so on. \n",
    "\n",
    "- In each file, the first row will have the headers \"Name, Affiliation\", etc, and each of the subsequent rows will consist of the details of the scientists. Each scientist will occupy one complete row.\n",
    "\n",
    "- The delimiter has been chosen to be `'\\t'`, because comma is pretty common in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810cda9b-edb1-4c51-a1b0-531c1f83ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f2789-b5a7-4eba-bea4-34a34ee3c3cc",
   "metadata": {},
   "source": [
    "## Google Scholar Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e09df2e6-f187-43d9-addb-fffb60acdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_scholar():\n",
    "    \n",
    "    # URL to search for scientits. The keyword is 'physic', which will hopefull \n",
    "    # return most of the physics scientist. The Indian search is enforced through\n",
    "    # the domains .ac.in and .res.in. Currently searches only through first page,\n",
    "    # needs to be extended to all pages\n",
    "    \n",
    "    url = \"https://scholar.google.co.in/citations?hl=en&view_op=search_authors&mauthors=physic+%2B+.ac.in+%7C+.res.in&btnG=\"\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content, features='lxml')\n",
    "    results = {}\n",
    "\n",
    "    for tag in soup.findAll('h3', attrs={'class': \"gs_ai_name\"}):\n",
    "\n",
    "        # obtain name, affiliation, interests and homepage (if exists)\n",
    "        name = tag.text\n",
    "        link = \"https://scholar.google.com\"+tag.next['href']\n",
    "        author_soup = bs(requests.get(link).content, features='lxml')\n",
    "        affil_tag = author_soup.find('div', attrs={'class':\"gsc_prf_il\"})\n",
    "        affil = affil_tag.text\n",
    "        try:\n",
    "            homepage = author_soup.find('a', text = \"Homepage\")['href']\n",
    "        except:\n",
    "            homepage = \"\"\n",
    "        interests = [child.text for child in author_soup.find('div', attrs={'class':\"gsc_prf_il\", 'id':\"gsc_prf_int\"}).findChildren()]\n",
    "\n",
    "        data = [name, affil, homepage, ', '.join(interests)]\n",
    "        \n",
    "        # append data for this scientist to the dictionary\n",
    "        for interest in interests:\n",
    "            \n",
    "            # sanitise interest by changing space to\n",
    "            # _ and converting all to lower case\n",
    "            interest_sanitised = interest.replace(' ', '_').lower()\n",
    "            \n",
    "            # create key if does not exist\n",
    "            if interest_sanitised not in results:\n",
    "                results[interest_sanitised] = [data]\n",
    "            else:\n",
    "                results[interest_sanitised].append(data)\n",
    "        \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
