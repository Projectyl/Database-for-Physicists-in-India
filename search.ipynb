{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31cb4a42-33a3-4a87-a31e-6eba13a95aa7",
   "metadata": {},
   "source": [
    "# Database Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "810cda9b-edb1-4c51-a1b0-531c1f83ed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f2789-b5a7-4eba-bea4-34a34ee3c3cc",
   "metadata": {},
   "source": [
    "## Google Scholar Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09df2e6-f187-43d9-addb-fffb60acdf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_scholar():\n",
    "    \n",
    "    # URL to search for scientits. The keyword is 'physic', which will hopefull \n",
    "    # return most of the physics scientist. The Indian search is enforced through\n",
    "    # the domains .ac.in and .res.in. Currently searches only through first page,\n",
    "    # needs to be extended to all pages\n",
    "    \n",
    "    url = \"https://scholar.google.co.in/citations?hl=en&view_op=search_authors&mauthors=physic+%2B+.ac.in+%7C+.res.in&btnG=\"\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content, features='lxml')\n",
    "    results = {}\n",
    "\n",
    "    for tag in soup.findAll('h3', attrs={'class': \"gs_ai_name\"}):\n",
    "\n",
    "        # obtain name, affiliation, interests and homepage (if exists)\n",
    "        name = tag.text\n",
    "        link = \"https://scholar.google.com\"+tag.next['href']\n",
    "        author_soup = bs(requests.get(link).content, features='lxml')\n",
    "        affil_tag = author_soup.find('div', attrs={'class':\"gsc_prf_il\"})\n",
    "        affil = affil_tag.text\n",
    "        try:\n",
    "            homepage = author_soup.find('a', text = \"Homepage\")['href']\n",
    "        except:\n",
    "            homepage = \"\"\n",
    "        interests = [child.text for child in author_soup.find('div', attrs={'class':\"gsc_prf_il\", 'id':\"gsc_prf_int\"}).findChildren()]\n",
    "\n",
    "        data = [name, affil, homepage, ', '.join(interests)]\n",
    "        \n",
    "        # append data for this scientist to the dictionary\n",
    "        for interest in interests:\n",
    "            \n",
    "            # sanitise interest by changing space to\n",
    "            # _ and converting all to lower case\n",
    "            interest_sanitised = interest.replace(' ', '_').lower()\n",
    "            \n",
    "            # create key if does not exist\n",
    "            if interest_sanitised not in results:\n",
    "                results[interest_sanitised] = [data]\n",
    "            else:\n",
    "                results[interest_sanitised].append(data)\n",
    "        \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
